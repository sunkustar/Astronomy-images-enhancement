{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to index mapping: {'0n': 0, '1n': 1, '2n': 2, '3n': 3, '4n': 4, '5n': 5, '6n': 6, '7n': 7, '8n': 8, '9n': 9}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "# Update transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root='/home/vamsi/cv/project/neww/Image-Super-Resolution-via-Iterative-Refinement/classs/share_it100', transform=transform)\n",
    "\n",
    "# Define split sizes\n",
    "train_size = int(0.9 * len(dataset))  # 90% training\n",
    "val_size = len(dataset) - train_size  # 20% validation\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Check class labels\n",
    "print(\"Class to index mapping:\", dataset.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained ViT model\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "\n",
    "# Modify the classifier head for the number of classes\n",
    "num_classes = len(dataset.classes)\n",
    "model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Training Loss: 2.8197\n",
      "Validation Loss: 2.2305, Validation Accuracy: 22.32%\n",
      "\n",
      "Epoch 2/50\n",
      "Training Loss: 2.2654\n",
      "Validation Loss: 2.1049, Validation Accuracy: 26.79%\n",
      "\n",
      "Epoch 3/50\n",
      "Training Loss: 2.1565\n",
      "Validation Loss: 2.1510, Validation Accuracy: 16.07%\n",
      "\n",
      "Epoch 4/50\n",
      "Training Loss: 2.1771\n",
      "Validation Loss: 2.1603, Validation Accuracy: 16.96%\n",
      "\n",
      "Epoch 5/50\n",
      "Training Loss: 2.1192\n",
      "Validation Loss: 2.2214, Validation Accuracy: 23.21%\n",
      "\n",
      "Epoch 6/50\n",
      "Training Loss: 2.1036\n",
      "Validation Loss: 1.9056, Validation Accuracy: 25.00%\n",
      "\n",
      "Epoch 7/50\n",
      "Training Loss: 2.0486\n",
      "Validation Loss: 1.9812, Validation Accuracy: 24.11%\n",
      "\n",
      "Epoch 8/50\n",
      "Training Loss: 2.0082\n",
      "Validation Loss: 1.9557, Validation Accuracy: 31.25%\n",
      "\n",
      "Epoch 9/50\n",
      "Training Loss: 1.9993\n",
      "Validation Loss: 1.8982, Validation Accuracy: 26.79%\n",
      "\n",
      "Epoch 10/50\n",
      "Training Loss: 1.9410\n",
      "Validation Loss: 2.0771, Validation Accuracy: 22.32%\n",
      "\n",
      "Epoch 11/50\n",
      "Training Loss: 1.9605\n",
      "Validation Loss: 1.9822, Validation Accuracy: 24.11%\n",
      "\n",
      "Epoch 12/50\n",
      "Training Loss: 1.9739\n",
      "Validation Loss: 1.8987, Validation Accuracy: 29.46%\n",
      "\n",
      "Epoch 13/50\n",
      "Training Loss: 1.9807\n",
      "Validation Loss: 1.9518, Validation Accuracy: 25.00%\n",
      "\n",
      "Epoch 14/50\n",
      "Training Loss: 1.9562\n",
      "Validation Loss: 1.9248, Validation Accuracy: 25.89%\n",
      "\n",
      "Epoch 15/50\n",
      "Training Loss: 1.9579\n",
      "Validation Loss: 1.8163, Validation Accuracy: 32.14%\n",
      "\n",
      "Epoch 16/50\n",
      "Training Loss: 1.9542\n",
      "Validation Loss: 1.8598, Validation Accuracy: 30.36%\n",
      "\n",
      "Epoch 17/50\n",
      "Training Loss: 1.9484\n",
      "Validation Loss: 1.8737, Validation Accuracy: 33.04%\n",
      "\n",
      "Epoch 18/50\n",
      "Training Loss: 1.9055\n",
      "Validation Loss: 1.8921, Validation Accuracy: 28.57%\n",
      "\n",
      "Epoch 19/50\n",
      "Training Loss: 2.2100\n",
      "Validation Loss: 2.1344, Validation Accuracy: 27.68%\n",
      "\n",
      "Epoch 20/50\n",
      "Training Loss: 2.1800\n",
      "Validation Loss: 2.0121, Validation Accuracy: 18.75%\n",
      "\n",
      "Epoch 21/50\n",
      "Training Loss: 2.0961\n",
      "Validation Loss: 2.1143, Validation Accuracy: 23.21%\n",
      "\n",
      "Epoch 22/50\n",
      "Training Loss: 2.0189\n",
      "Validation Loss: 1.9628, Validation Accuracy: 23.21%\n",
      "\n",
      "Epoch 23/50\n",
      "Training Loss: 2.0037\n",
      "Validation Loss: 2.0215, Validation Accuracy: 23.21%\n",
      "\n",
      "Epoch 24/50\n",
      "Training Loss: 1.9827\n",
      "Validation Loss: 1.9484, Validation Accuracy: 22.32%\n",
      "\n",
      "Epoch 25/50\n",
      "Training Loss: 1.9615\n",
      "Validation Loss: 1.9331, Validation Accuracy: 25.00%\n",
      "\n",
      "Epoch 26/50\n",
      "Training Loss: 1.9369\n",
      "Validation Loss: 2.1296, Validation Accuracy: 16.96%\n",
      "\n",
      "Epoch 27/50\n",
      "Training Loss: 1.9542\n",
      "Validation Loss: 2.0049, Validation Accuracy: 21.43%\n",
      "\n",
      "Epoch 28/50\n",
      "Training Loss: 1.9540\n",
      "Validation Loss: 2.0094, Validation Accuracy: 25.00%\n",
      "\n",
      "Epoch 29/50\n",
      "Training Loss: 1.9657\n",
      "Validation Loss: 2.0908, Validation Accuracy: 25.89%\n",
      "\n",
      "Epoch 30/50\n",
      "Training Loss: 1.9746\n",
      "Validation Loss: 2.0312, Validation Accuracy: 19.64%\n",
      "\n",
      "Epoch 31/50\n",
      "Training Loss: 1.9809\n",
      "Validation Loss: 1.9517, Validation Accuracy: 25.00%\n",
      "\n",
      "Epoch 32/50\n",
      "Training Loss: 1.9747\n",
      "Validation Loss: 1.9763, Validation Accuracy: 32.14%\n",
      "\n",
      "Epoch 33/50\n",
      "Training Loss: 2.0247\n",
      "Validation Loss: 1.9688, Validation Accuracy: 21.43%\n",
      "\n",
      "Epoch 34/50\n",
      "Training Loss: 1.9515\n",
      "Validation Loss: 2.0106, Validation Accuracy: 16.96%\n",
      "\n",
      "Epoch 35/50\n",
      "Training Loss: 1.9343\n",
      "Validation Loss: 1.9575, Validation Accuracy: 25.00%\n",
      "\n",
      "Epoch 36/50\n",
      "Training Loss: 1.8995\n",
      "Validation Loss: 1.8784, Validation Accuracy: 29.46%\n",
      "\n",
      "Epoch 37/50\n",
      "Training Loss: 1.9703\n",
      "Validation Loss: 1.8901, Validation Accuracy: 27.68%\n",
      "\n",
      "Epoch 38/50\n",
      "Training Loss: 1.9578\n",
      "Validation Loss: 2.1119, Validation Accuracy: 19.64%\n",
      "\n",
      "Epoch 39/50\n",
      "Training Loss: 1.9625\n",
      "Validation Loss: 1.8244, Validation Accuracy: 33.93%\n",
      "\n",
      "Epoch 40/50\n",
      "Training Loss: 1.9008\n",
      "Validation Loss: 1.7946, Validation Accuracy: 35.71%\n",
      "\n",
      "Epoch 41/50\n",
      "Training Loss: 1.9306\n",
      "Validation Loss: 2.0251, Validation Accuracy: 23.21%\n",
      "\n",
      "Epoch 42/50\n",
      "Training Loss: 2.0579\n",
      "Validation Loss: 2.0175, Validation Accuracy: 22.32%\n",
      "\n",
      "Epoch 43/50\n",
      "Training Loss: 2.0085\n",
      "Validation Loss: 2.0713, Validation Accuracy: 25.00%\n",
      "\n",
      "Epoch 44/50\n",
      "Training Loss: 1.9526\n",
      "Validation Loss: 2.0135, Validation Accuracy: 26.79%\n",
      "\n",
      "Epoch 45/50\n",
      "Training Loss: 1.9663\n",
      "Validation Loss: 2.0298, Validation Accuracy: 26.79%\n",
      "\n",
      "Epoch 46/50\n",
      "Training Loss: 1.9659\n",
      "Validation Loss: 1.9066, Validation Accuracy: 22.32%\n",
      "\n",
      "Epoch 47/50\n",
      "Training Loss: 2.0164\n",
      "Validation Loss: 2.2467, Validation Accuracy: 19.64%\n",
      "\n",
      "Epoch 48/50\n",
      "Training Loss: 2.0235\n",
      "Validation Loss: 1.9409, Validation Accuracy: 28.57%\n",
      "\n",
      "Epoch 49/50\n",
      "Training Loss: 1.9331\n",
      "Validation Loss: 1.9984, Validation Accuracy: 25.00%\n",
      "\n",
      "Epoch 50/50\n",
      "Training Loss: 1.9685\n",
      "Validation Loss: 1.9910, Validation Accuracy: 25.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sr3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
